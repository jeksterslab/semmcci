---
title: "Benchmark: Comparing the Monte Carlo Method with Nonparametric Bootstrapping"
author: "Ivan Jacob Agaloos Pesigan"
date: "`r Sys.Date()`"
bibliography: "vignettes.bib"
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
nocite: |
  @Pesigan-Cheung-2024
output:
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Benchmark: Comparing the Monte Carlo Method with Nonparametric Bootstrapping}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<!-- vignettes/benchmark-complete.Rmd is generated from .setup/vignettes/benchmark-complete.Rmd.orig. Please edit that file -->

```{r}
#| include = FALSE
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.path = "fig-vignettes-benchmark-",
  fig.cap = "",
  fig.width = 11,
  fig.height = 8,
  fig.retina = 2,
  dpi = 300,
  comment = "#>"
)
```

```{r}
#| echo = FALSE,
#| message = FALSE,
#| warning = FALSE
root <- rprojroot::is_rstudio_project
dir <- root$find_file(
  ".setup",
  "data-raw",
  "benchmark"
)
if (!dir.exists(dir)) {
  dir.create(
    dir,
    recursive = TRUE
  )
}
```

```{r}
#| include = FALSE
set.seed(42)
```

We compare the Monte Carlo (MC) method with nonparametric bootstrapping (NB) using the simple mediation model with complete data.
One advantage of MC over NB is speed.
This is because the model is only fitted once in MC whereas it is fitted many times in NB.

```{r}
#| message = FALSE
library(semmcci)
library(lavaan)
library(microbenchmark)
```

## Data

```{r}
n <- 1000
a <- 0.50
b <- 0.50
cp <- 0.25
s2_em <- 1 - a^2
s2_ey <- 1 - cp^2 - a^2 * b^2 - b^2 * s2_em - 2 * cp * a * b
em <- rnorm(n = n, mean = 0, sd = sqrt(s2_em))
ey <- rnorm(n = n, mean = 0, sd = sqrt(s2_ey))
X <- rnorm(n = n)
M <- a * X + em
Y <- cp * X + b * M + ey
df <- data.frame(X, M, Y)
```

## Model Specification

The indirect effect is defined by the product of the slopes
of paths `X` to `M` labeled as `a` and `M` to `Y` labeled as `b`.
In this example, we are interested in the confidence intervals of `indirect`
defined as the product of `a` and `b` using the `:=` operator
in the `lavaan` model syntax.

```{r}
model <- "
  Y ~ cp * X + b * M
  M ~ a * X
  X ~~ X
  indirect := a * b
  direct := cp
  total := cp + (a * b)
"
```

## Model Fitting

We can now fit the model using the `sem()` function from `lavaan`.

```{r}
fit <- sem(data = df, model = model)
```

## Monte Carlo Confidence Intervals

The `fit` `lavaan` object can then be passed to the `MC()` function from `semmcci`
to generate Monte Carlo confidence intervals.

```{r}
MC(fit, R = 100L, alpha = 0.05)
```

## Nonparametric Bootstrap Confidence Intervals

Nonparametric bootstrap confidence intervals can be generated in `lavaan` using the following.

```{r}
#| message = FALSE,
#| warning = FALSE
parameterEstimates(
  sem(
    data = df,
    model = model,
    se = "bootstrap",
    bootstrap = 100L
  )
)
```

## Benchmark

### Arguments

```{r}
#| include = FALSE
production <- TRUE
if (production) {
  R <- 1000L
  B <- 1000L
} else {
  R <- 10L
  B <- 10L
}
```

```{r}
#| echo = FALSE
variables <- c(
  "R",
  "B"
)
values <- c(
  R,
  B
)
notes <- c(
  "Number of Monte Carlo replications.",
  "Number of bootstrap samples."
)
tab <- cbind(
  Variables = variables,
  Values = values,
  Notes = notes
)
knitr::kable(
  x = tab
)
```

```{r}
#| echo = FALSE,
#| message = FALSE,
#| warning = FALSE
benchmark_complete_01_file <- file.path(
  dir,
  "benchmark-complete-01.Rds"
)
if (!file.exists(benchmark_complete_01_file)) {
  benchmark_complete_01 <- microbenchmark(
    MC = {
      fit <- sem(
        data = df,
        model = model
      )
      MC(
        fit,
        R = R,
        decomposition = "chol",
        pd = FALSE
      )
    },
    NB = sem(
      data = df,
      model = model,
      se = "bootstrap",
      bootstrap = B
    ),
    times = 10
  )
  saveRDS(
    object = benchmark_complete_01,
    file = benchmark_complete_01_file,
    compress = "xz"
  )
}
benchmark_complete_01 <- readRDS(
  file = benchmark_complete_01_file
)
```

```{r}
#| eval = FALSE
benchmark_complete_01 <- microbenchmark(
  MC = {
    fit <- sem(
      data = df,
      model = model
    )
    MC(
      fit,
      R = R,
      decomposition = "chol",
      pd = FALSE
    )
  },
  NB = sem(
    data = df,
    model = model,
    se = "bootstrap",
    bootstrap = B
  ),
  times = 10
)
```

### Summary of Benchmark Results

```{r}
summary(benchmark_complete_01, unit = "ms")
```

### Summary of Benchmark Results Relative to the Faster Method

```{r}
summary(benchmark_complete_01, unit = "relative")
```

## Plot

```{r}
#| echo = FALSE,
#| warning = FALSE,
#| message = FALSE
boxplot(benchmark_complete_01)
```

## Benchmark - Monte Carlo Method with Precalculated Estimates

```{r}
#| echo = FALSE,
#| message = FALSE,
#| warning = FALSE
fit <- sem(
  data = df,
  model = model
)
benchmark_complete_02_file <- file.path(
  dir,
  "benchmark-complete-02.Rds"
)
if (!file.exists(benchmark_complete_02_file)) {
  benchmark_complete_02 <- microbenchmark(
    MC = MC(
      fit,
      R = R,
      decomposition = "chol",
      pd = FALSE
    ),
    NB = sem(
      data = df,
      model = model,
      se = "bootstrap",
      bootstrap = B
    ),
    times = 10
  )
  saveRDS(
    object = benchmark_complete_02,
    file = benchmark_complete_02_file,
    compress = "xz"
  )
}
benchmark_complete_02 <- readRDS(
  file = benchmark_complete_02_file
)
```

```{r}
#| eval = FALSE
fit <- sem(
  data = df,
  model = model
)
benchmark_complete_02 <- microbenchmark(
  MC = MC(
    fit,
    R = R,
    decomposition = "chol",
    pd = FALSE
  ),
  NB = sem(
    data = df,
    model = model,
    se = "bootstrap",
    bootstrap = B
  ),
  times = 10
)
```

### Summary of Benchmark Results

```{r}
summary(benchmark_complete_02, unit = "ms")
```

### Summary of Benchmark Results Relative to the Faster Method

```{r}
summary(benchmark_complete_02, unit = "relative")
```

## Plot

```{r}
#| echo = FALSE,
#| warning = FALSE,
#| message = FALSE
boxplot(benchmark_complete_02)
```

## References
